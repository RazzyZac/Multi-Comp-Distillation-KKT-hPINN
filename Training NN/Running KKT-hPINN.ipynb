{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61543314",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(model='KKThPINN', model_id='MODELID', input_dim=5, hidden_dim=32, hidden_num=1, z0_dim=8, optimizer='adam', epochs=350, batch_size=16, lr=0.0001, mu=1, max_subiter=500, eta=0.8, sigma=2, mu_safe=1000000000.0, dataset_type='distillation', dataset_path='nonsharp_dist_simple.csv', val_ratio=0.1, job='train', runs=1)"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'for num in np.linspace(32,40, 9):\\n    command = f\"python main.py --model KKThPINN --model_id MODELID --input_dim 5 --hidden_dim {int(num)} --hidden_num 1 --z0_dim 8 --epochs 350 --dataset_type distillation --dataset_path nonsharp_dist_simple.csv --val_ratio .1 --job train --runs 1\"\\n    subprocess.run(command, shell=True)'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "n_test is \n",
      "3000\n",
      "<torch.utils.data.dataset.Subset object at 0x000001ED51E0ECA0>\n",
      "n_test is \n",
      "3000\n",
      "<torch.utils.data.dataset.Subset object at 0x000001ED6577A3A0>\n",
      "x_dim is \n",
      "5\n",
      "8\n",
      "type of A: torch.float64, type of B: torch.float64, type of b: torch.float64\n",
      "train set size: 10503, val set size: 1500, test set size: 3000\n",
      "{'train_loader': <torch.utils.data.dataloader.DataLoader object at 0x000001ED1F8E2C70>, 'val_loader': <torch.utils.data.dataloader.DataLoader object at 0x000001ED1F8E2C10>, 'test_loader': <torch.utils.data.dataloader.DataLoader object at 0x000001ED6577A0D0>, 'dataset': <utils.Nonsharp_Dist object at 0x000001ED65FE8F70>, 'A': tensor([[155.7334,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "        [  0.0000, 173.2469,   0.0000,   0.0000,   0.0000],\n",
      "        [  0.0000,   0.0000, 173.3732,   0.0000,   0.0000]],\n",
      "       dtype=torch.float64), 'B': tensor([[-123.3888,    0.0000,    0.0000,  -83.9591,    0.0000,    0.0000,\n",
      "            0.0000,    0.0000],\n",
      "        [   0.0000, -117.2778,    0.0000,    0.0000, -117.0948,    0.0000,\n",
      "            0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000, -100.8314,    0.0000,    0.0000, -127.2187,\n",
      "            0.0000,    0.0000]], dtype=torch.float64), 'b': tensor([[0.],\n",
      "        [0.],\n",
      "        [0.]], dtype=torch.float64), 'constrained_indexes': [0, 1, 2, 3, 4, 5], 'unconstrained_indexes': [6, 7]}\n",
      "A is \n",
      "tensor([[155.7334,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "        [  0.0000, 173.2469,   0.0000,   0.0000,   0.0000],\n",
      "        [  0.0000,   0.0000, 173.3732,   0.0000,   0.0000]],\n",
      "       dtype=torch.float64)\n",
      "Start Training...\n",
      "epoch: 00050 loss_train: 0.00200 loss_val: 0.00165 violation_train: 0.00000 violation_val: 0.00000\n",
      "epoch: 00100 loss_train: 0.00128 loss_val: 0.00100 violation_train: 0.00000 violation_val: 0.00000\n",
      "epoch: 00150 loss_train: 0.00111 loss_val: 0.00090 violation_train: 0.00000 violation_val: 0.00000\n",
      "epoch: 00200 loss_train: 0.00103 loss_val: 0.00084 violation_train: 0.00000 violation_val: 0.00000\n",
      "epoch: 00250 loss_train: 0.00098 loss_val: 0.00081 violation_train: 0.00000 violation_val: 0.00000\n",
      "epoch: 00300 loss_train: 0.00095 loss_val: 0.00079 violation_train: 0.00000 violation_val: 0.00000\n",
      "epoch: 00350 loss_train: 0.00093 loss_val: 0.00079 violation_train: 0.00000 violation_val: 0.00000\n",
      "Finished!\n",
      "A is \n",
      "tensor([[155.7334,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "        [  0.0000, 173.2469,   0.0000,   0.0000,   0.0000],\n",
      "        [  0.0000,   0.0000, 173.3732,   0.0000,   0.0000]],\n",
      "       dtype=torch.float64)\n",
      "{'rmse_total': 0.12983254264891744, 'rmse_unconstrained': 0.24713965661591186, 'rmse_constrained': 0.04505358002403927, 'violation': 9.189635934930207e-16}\n",
      "Saving standard model\n",
      "============= Diagnostic Run torch.onnx.export version 2.0.1+cu118 =============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n",
      "Wrote PyTorch Onnx model to KKThPINN_dist_simple 32.onnx\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import subprocess\n",
    "!python main.py --model KKThPINN --model_id MODELID --input_dim 5 --hidden_dim 32 --hidden_num 1 --z0_dim 8 --epochs 350 --dataset_type distillation --dataset_path nonsharp_dist_simple.csv --val_ratio .1 --job train --runs 1\n",
    "\"\"\"for num in np.linspace(32,40, 9):\n",
    "    command = f\"python main.py --model KKThPINN --model_id MODELID --input_dim 5 --hidden_dim {int(num)} --hidden_num 1 --z0_dim 8 --epochs 350 --dataset_type distillation --dataset_path nonsharp_dist_simple.csv --val_ratio .1 --job train --runs 1\"\n",
    "    subprocess.run(command, shell=True)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5fe701b",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MinMaxScaler, StandardScaler\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\__init__.py:87\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     73\u001b[0m     \u001b[38;5;66;03m# We are not importing the rest of scikit-learn during the build\u001b[39;00m\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;66;03m# process, as it may not be compiled yet\u001b[39;00m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     81\u001b[0m     \u001b[38;5;66;03m# later is linked to the OpenMP runtime to make it possible to introspect\u001b[39;00m\n\u001b[0;32m     82\u001b[0m     \u001b[38;5;66;03m# it and importing it first would fail if the OpenMP dll cannot be found.\u001b[39;00m\n\u001b[0;32m     83\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     84\u001b[0m         __check_build,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     85\u001b[0m         _distributor_init,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     86\u001b[0m     )\n\u001b[1;32m---> 87\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m clone\n\u001b[0;32m     88\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_show_versions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m show_versions\n\u001b[0;32m     90\u001b[0m     __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     91\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcalibration\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     92\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcluster\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    133\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshow_versions\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    134\u001b[0m     ]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py:19\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config_context, get_config\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InconsistentVersionWarning\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _IS_32BIT\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_estimator_html_repr\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _HTMLDocumentationLinkMixin, estimator_html_repr\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_metadata_requests\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _MetadataRequester, _routing_enabled\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\__init__.py:20\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_config\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataConversionWarning\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _joblib, metadata_routing\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_bunch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Bunch\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_estimator_html_repr\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m estimator_html_repr\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_joblib.py:7\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     _warnings\u001b[38;5;241m.\u001b[39msimplefilter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m# joblib imports may raise DeprecationWarning on certain Python\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m# versions\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjoblib\u001b[39;00m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mjoblib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      9\u001b[0m         Memory,\n\u001b[0;32m     10\u001b[0m         Parallel,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     20\u001b[0m         register_parallel_backend,\n\u001b[0;32m     21\u001b[0m     )\n\u001b[0;32m     24\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparallel_backend\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregister_parallel_backend\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__version__\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     38\u001b[0m ]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\__init__.py:120\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnumpy_pickle\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompressor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m register_compressor\n\u001b[1;32m--> 120\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparallel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Parallel\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparallel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m delayed\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparallel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cpu_count\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1007\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:986\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:680\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:846\u001b[0m, in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:941\u001b[0m, in \u001b[0;36mget_code\u001b[1;34m(self, fullname)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1039\u001b[0m, in \u001b[0;36mget_data\u001b[1;34m(self, path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils import data\n",
    "from models import NN, NNOPT,NNRelu\n",
    "\n",
    "dataset = np.array(pd.read_csv('nonsharp_dist.csv').values)\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(dataset)\n",
    "dataset = scaler.transform(dataset)\n",
    "\n",
    "x_dim = 8\n",
    "z_dim = 8\n",
    "xscale = []\n",
    "zscale = []\n",
    "for idx in range(x_dim):\n",
    "    xscale.append(scaler.data_range_[idx])\n",
    "for idx in range(z_dim):\n",
    "    zscale.append((scaler.data_range_[idx+x_dim]))\n",
    "print(xscale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2906b45b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
